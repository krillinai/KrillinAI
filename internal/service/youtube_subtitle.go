package service

import (
	"bufio"
	"context"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"strconv"
	"strings"
	"time"

	"krillin-ai/config"
	"krillin-ai/internal/storage"
	"krillin-ai/internal/types"
	"krillin-ai/log"
	"krillin-ai/pkg/util"

	"regexp"

	"go.uber.org/zap"
)

// VttWord è¡¨ç¤ºVTTæ–‡ä»¶ä¸­çš„ä¸€ä¸ªå•è¯åŠå…¶æ—¶é—´æˆ³ä¿¡æ¯
type VttWord struct {
	Text  string // å•è¯æ–‡æœ¬ï¼ŒåŒ…å«æ ‡ç‚¹ç¬¦å·
	Start string // å¼€å§‹æ—¶é—´æˆ³å­—ç¬¦ä¸² (HH:MM:SS.mmm)
	End   string // ç»“æŸæ—¶é—´æˆ³å­—ç¬¦ä¸² (HH:MM:SS.mmm)
	Num   int    // åºå·
}

type YoutubeSubtitleReq struct {
	TaskBasePath   string
	TaskId         string
	URL            string
	OriginLanguage string
	TargetLanguage string
	VttFile        string
	TaskPtr        *types.SubtitleTask
}

// YouTubeSubtitleService handles all operations related to YouTube subtitles.
type YouTubeSubtitleService struct {
	translator         *Translator
	timestampGenerator *TimestampGenerator
}

// NewYouTubeSubtitleService creates a new YouTubeSubtitleService.
func NewYouTubeSubtitleService() *YouTubeSubtitleService {
	return &YouTubeSubtitleService{
		translator:         NewTranslator(),
		timestampGenerator: NewTimestampGenerator(),
	}
}

// Process handles the entire workflow for YouTube subtitles, from downloading to processing.
func (s *YouTubeSubtitleService) Process(ctx context.Context, req *YoutubeSubtitleReq) (string, error) {
	// 1. Download subtitle file
	vttFile, err := s.downloadYouTubeSubtitle(ctx, req)
	if err != nil {
		// Return error to let the caller handle fallback (e.g., audio transcription)
		return "", err
	}

	req.VttFile = vttFile

	// 2. Process the downloaded subtitle file
	log.GetLogger().Info("Successfully downloaded YouTube subtitles, processing...", zap.String("taskId", req.TaskId))
	return s.processYouTubeSubtitle(ctx, req)
}

func (s *YouTubeSubtitleService) parseVttTime(timeStr string) (float64, error) {
	// VTT format: HH:MM:SS.ms or MM:SS.ms
	parts := strings.Split(timeStr, ":")
	var h, m, sec, ms int
	var err error

	if len(parts) == 3 { // HH:MM:SS.ms
		h, err = strconv.Atoi(parts[0])
		if err != nil {
			return 0, err
		}
		m, err = strconv.Atoi(parts[1])
		if err != nil {
			return 0, err
		}
		secParts := strings.Split(parts[2], ".")
		sec, err = strconv.Atoi(secParts[0])
		if err != nil {
			return 0, err
		}
		ms, err = strconv.Atoi(secParts[1])
		if err != nil {
			return 0, err
		}
	} else if len(parts) == 2 { // MM:SS.ms
		m, err = strconv.Atoi(parts[0])
		if err != nil {
			return 0, err
		}
		secParts := strings.Split(parts[1], ".")
		sec, err = strconv.Atoi(secParts[0])
		if err != nil {
			return 0, err
		}
		ms, err = strconv.Atoi(secParts[1])
		if err != nil {
			return 0, err
		}
	} else {
		return 0, fmt.Errorf("invalid time format: %s", timeStr)
	}

	return float64(h)*3600 + float64(m)*60 + float64(sec) + float64(ms)/1000, nil
}

// ä½¿ç”¨yt-dlpä¸‹è½½YouTubeè§†é¢‘çš„å­—å¹•æ–‡ä»¶
func (s *YouTubeSubtitleService) downloadYouTubeSubtitle(ctx context.Context, req *YoutubeSubtitleReq) (string, error) {
	if !strings.Contains(req.URL, "youtube.com") {
		return "", fmt.Errorf("downloadYouTubeSubtitle: not a YouTube link")
	}

	// æå–YouTubeè§†é¢‘ID
	videoID, err := util.GetYouTubeID(req.URL)
	if err != nil {
		return "", fmt.Errorf("downloadYouTubeSubtitle: failed to extract video ID: %w", err)
	}

	// ç¡®å®šè¦ä¸‹è½½çš„å­—å¹•è¯­è¨€
	subtitleLang := util.MapLanguageForYouTube(req.OriginLanguage)

	// æ„é€ yt-dlpå‘½ä»¤å‚æ•°ï¼Œä½¿ç”¨è§†é¢‘IDä½œä¸ºæ–‡ä»¶å
	outputPattern := filepath.Join(req.TaskBasePath, videoID+".%(ext)s")
	cmdArgs := []string{
		"--write-auto-subs",
		"--sub-langs", subtitleLang,
		"--skip-download",
		"-o", outputPattern,
		req.URL,
	}

	// æ·»åŠ ä»£ç†è®¾ç½®
	if config.Conf.App.Proxy != "" {
		cmdArgs = append(cmdArgs, "--proxy", config.Conf.App.Proxy)
	}

	// æ·»åŠ cookies
	cmdArgs = append(cmdArgs, "--cookies", "./cookies.txt")

	// æ·»åŠ ffmpegè·¯å¾„
	if storage.FfmpegPath != "ffmpeg" {
		cmdArgs = append(cmdArgs, "--ffmpeg-location", storage.FfmpegPath)
	}

	log.GetLogger().Info("downloadYouTubeSubtitle starting", zap.Any("taskId", req.TaskId), zap.Any("cmdArgs", cmdArgs))

	// æ·»åŠ é‡è¯•æœºåˆ¶
	maxAttempts := 3
	var lastErr error

	for attempt := 0; attempt < maxAttempts; attempt++ {
		log.GetLogger().Info("Attempting to download YouTube subtitle",
			zap.Any("taskId", req.TaskId),
			zap.Int("attempt", attempt+1),
			zap.Int("maxAttempts", maxAttempts))

		cmd := exec.Command(storage.YtdlpPath, cmdArgs...)
		output, err := cmd.CombinedOutput()

		if err == nil {
			log.GetLogger().Info("downloadYouTubeSubtitle completed", zap.Any("taskId", req.TaskId), zap.String("output", string(output)))

			// æŸ¥æ‰¾ä¸‹è½½çš„å­—å¹•æ–‡ä»¶
			subtitleFile, err := s.findDownloadedSubtitleFile(req.TaskBasePath, subtitleLang, videoID)
			if err != nil {
				log.GetLogger().Error("downloadYouTubeSubtitle findDownloadedSubtitleFile error", zap.Any("stepParam", req), zap.Error(err))
				return "", fmt.Errorf("downloadYouTubeSubtitle findDownloadedSubtitleFile error: %w", err)
			}

			log.GetLogger().Info("downloadYouTubeSubtitle found subtitle file", zap.Any("taskId", req.TaskId), zap.String("subtitleFile", subtitleFile))
			return subtitleFile, nil
		}

		lastErr = err
		log.GetLogger().Warn("downloadYouTubeSubtitle attempt failed",
			zap.Any("taskId", req.TaskId),
			zap.Int("attempt", attempt+1),
			zap.String("output", string(output)),
			zap.Error(err))

		// å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡è¯•
		if attempt < maxAttempts-1 {
			time.Sleep(time.Duration(attempt+1) * time.Second)
		}
	}

	log.GetLogger().Error("downloadYouTubeSubtitle failed after all attempts", zap.Any("req", req), zap.Error(lastErr))
	return "", fmt.Errorf("downloadYouTubeSubtitle yt-dlp error after %d attempts: %w", maxAttempts, lastErr)
}

// æŸ¥æ‰¾ä¸‹è½½çš„å­—å¹•æ–‡ä»¶
func (s *YouTubeSubtitleService) findDownloadedSubtitleFile(taskBasePath, language, videoID string) (string, error) {
	// æ”¯æŒçš„å­—å¹•æ–‡ä»¶æ‰©å±•å
	extensions := []string{".vtt", ".srt"}

	// æ„é€ é¢„æœŸçš„æ–‡ä»¶åæ¨¡å¼ï¼š{videoID}.{ext}
	for _, ext := range extensions {
		expectedFileName := fmt.Sprintf("%s.%s", videoID, ext)
		expectedPath := filepath.Join(taskBasePath, expectedFileName)

		// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
		if _, err := os.Stat(expectedPath); err == nil {
			return expectedPath, nil
		}
	}

	// å¦‚æœé¢„æœŸçš„æ–‡ä»¶åä¸å­˜åœ¨ï¼Œåˆ™å›é€€åˆ°éå†ç›®å½•çš„æ–¹å¼ï¼ˆå…¼å®¹æ—§çš„å‘½åæ–¹å¼ï¼‰
	err := filepath.Walk(taskBasePath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		if info.IsDir() {
			return nil
		}

		fileName := info.Name()
		for _, ext := range extensions {
			// æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«è§†é¢‘IDã€è¯­è¨€ä»£ç å’Œå¯¹åº”æ‰©å±•å
			if strings.Contains(fileName, videoID) && strings.Contains(fileName, language) && strings.HasSuffix(fileName, ext) {
				return fmt.Errorf("found:%s", path) // ä½¿ç”¨erroræ¥è¿”å›æ‰¾åˆ°çš„æ–‡ä»¶è·¯å¾„
			}
		}
		return nil
	})

	if err != nil && strings.HasPrefix(err.Error(), "found:") {
		return strings.TrimPrefix(err.Error(), "found:"), nil
	}

	return "", fmt.Errorf("subtitle file not found for video ID: %s, language: %s", videoID, language)
}

// å¤„ç†YouTubeå­—å¹•æ–‡ä»¶ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼å¹¶è¿›è¡Œç¿»è¯‘
func (s *YouTubeSubtitleService) processYouTubeSubtitle(ctx context.Context, req *YoutubeSubtitleReq) (string, error) {
	if req.VttFile == "" {
		return "", fmt.Errorf("processYouTubeSubtitle: no original subtitle file found")
	}

	log.GetLogger().Info("processYouTubeSubtitle start", zap.Any("taskId", req.TaskId), zap.String("subtitleFile", req.VttFile))

	bilingualSrtFile := filepath.Join(req.TaskBasePath, types.SubtitleTaskBilingualSrtFileName)
	// 1. è½¬æ¢VTTåˆ°SRTæ ¼å¼
	err := s.ConvertVttToSrt(req, bilingualSrtFile)
	if err != nil {
		return "", fmt.Errorf("processYouTubeSubtitle convertToSrtFormat error: %w", err)
	}

	log.GetLogger().Info("processYouTubeSubtitle converted to SRT", zap.Any("taskId", req.TaskId), zap.String("srtFile", bilingualSrtFile))

	return bilingualSrtFile, nil
}

// ExtractWordsFromVtt ä»VTTæ–‡ä»¶ä¸­æå–æ‰€æœ‰å•è¯åŠå…¶æ—¶é—´æˆ³ä¿¡æ¯
func (s *YouTubeSubtitleService) ExtractWordsFromVtt(vttFile string) ([]VttWord, error) {
	// è®°å½•æ­£åœ¨å°è¯•æ‰“å¼€çš„æ–‡ä»¶è·¯å¾„
	log.GetLogger().Info("Attempting to open VTT file", zap.String("filePath", vttFile))

	file, err := os.Open(vttFile)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–VTTæ–‡ä»¶å¤±è´¥: %w", err)
	}
	defer file.Close()

	var words []VttWord
	scanner := bufio.NewScanner(file)
	var blockStartTime, blockEndTime string
	wordNum := 0

	// åŒ¹é…æ—¶é—´æˆ³è¡Œçš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆæ”¯æŒæœ‰ç©ºæ ¼å’Œæ— ç©ºæ ¼çš„æ ¼å¼ï¼‰
	timestampLineRegex := regexp.MustCompile(`^(\d{2}:\d{2}:\d{2}\.\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}\.\d{3})`)
	// åŒ¹é…å•è¯çº§æ—¶é—´æˆ³çš„æ­£åˆ™è¡¨è¾¾å¼
	wordTimeRegex := regexp.MustCompile(`<(\d{2}:\d{2}:\d{2}\.\d{3})>`)
	// æ¸…ç†æ ·å¼æ ‡ç­¾
	styleTagRegex := regexp.MustCompile(`</?c[^>]*>`)

	log.GetLogger().Debug("å¼€å§‹è§£æVTTæ–‡ä»¶", zap.String("æ–‡ä»¶", vttFile))

	// ç”¨äºè·Ÿè¸ªå·²å¤„ç†çš„å•è¯ï¼Œé¿å…é‡å¤
	processedWords := make(map[string]bool)
	// ç”¨äºè·Ÿè¸ªå•è¯æ–‡æœ¬ï¼Œé¿å…åŒä¸€ä¸ªå•è¯é‡å¤æ·»åŠ 
	seenWordTexts := make(map[string]bool)

	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())

		// è·³è¿‡ç©ºè¡Œå’Œå¤´éƒ¨ä¿¡æ¯
		if line == "" || strings.HasPrefix(line, "WEBVTT") ||
			strings.HasPrefix(line, "Kind:") || strings.HasPrefix(line, "Language:") {
			continue
		}

		// æ£€æŸ¥æ˜¯å¦æ˜¯æ—¶é—´æˆ³è¡Œï¼ˆå¯èƒ½åŒ…å«alignç­‰å±æ€§ï¼‰
		if matches := timestampLineRegex.FindStringSubmatch(line); len(matches) >= 3 {
			blockStartTime = matches[1]
			blockEndTime = matches[2]
			log.GetLogger().Debug("å‘ç°æ—¶é—´æˆ³", zap.String("å¼€å§‹", blockStartTime), zap.String("ç»“æŸ", blockEndTime))
			continue
		}

		// å¦‚æœä¸æ˜¯æ—¶é—´æˆ³è¡Œï¼Œä¸”æœ‰æœ‰æ•ˆçš„æ—¶é—´æˆ³ä¿¡æ¯ï¼Œåˆ™å¤„ç†å†…å®¹
		if blockStartTime != "" && blockEndTime != "" && line != "" {
			// é¦–å…ˆæ¸…ç†HTMLå®ä½“å’Œç‰¹æ®Šå­—ç¬¦
			cleanedLine := s.cleanVttText(line)

			// å¦‚æœæ¸…ç†åä¸ºç©ºæˆ–åªæ˜¯ç©ºç™½å­—ç¬¦ï¼Œè·³è¿‡
			if strings.TrimSpace(cleanedLine) == "" {
				continue
			}

			// ä¼˜å…ˆå¤„ç†åŒ…å«å†…è”æ—¶é—´æˆ³çš„è¡Œï¼ˆè¿™äº›æ˜¯çœŸæ­£çš„å•è¯çº§æ—¶é—´æˆ³æ•°æ®ï¼‰
			if wordTimeRegex.MatchString(cleanedLine) {
				// å¤„ç†åŒ…å«å•è¯çº§æ—¶é—´æˆ³çš„è¡Œ
				styleCleaned := styleTagRegex.ReplaceAllString(cleanedLine, "")
				wordsFromLine := s.parseWordsWithTimestamps(styleCleaned, blockStartTime, blockEndTime, &wordNum)

				// æ·»åŠ å¸¦æ—¶é—´æˆ³çš„å•è¯ï¼Œè¿™äº›æœ‰æ›´é«˜ä¼˜å…ˆçº§
				for _, word := range wordsFromLine {
					// å†æ¬¡æ¸…ç†å•è¯æ–‡æœ¬
					word.Text = s.cleanVttText(word.Text)
					if strings.TrimSpace(word.Text) == "" {
						continue // è·³è¿‡ç©ºçš„å•è¯
					}

					wordKey := fmt.Sprintf("%s-%s-%s", word.Text, word.Start, word.End)
					if !processedWords[wordKey] {
						words = append(words, word)
						processedWords[wordKey] = true
						// åŒæ—¶è®°å½•è¿™ä¸ªå•è¯æ–‡æœ¬å·²ç»è¢«å¤„ç†è¿‡
						seenWordTexts[strings.ToLower(word.Text)] = true
						log.GetLogger().Debug("æ·»åŠ å¸¦æ—¶é—´æˆ³çš„å•è¯",
							zap.String("æ–‡æœ¬", word.Text),
							zap.String("å¼€å§‹", word.Start),
							zap.String("ç»“æŸ", word.End))
					}
				}
			} else {
				// å¯¹äºæ²¡æœ‰å†…è”æ—¶é—´æˆ³çš„è¡Œï¼Œéœ€è¦æ›´ä¸¥æ ¼çš„åˆ¤æ–­
				trimmedLine := strings.TrimSpace(cleanedLine)

				// è·³è¿‡æ˜æ˜¾çš„é‡å¤å†…å®¹è¡Œï¼ˆé€šå¸¸æ˜¯å®Œæ•´å¥å­çš„é‡å¤ï¼‰
				if s.isLikelyRepeatContent(trimmedLine) {
					log.GetLogger().Debug("è·³è¿‡é‡å¤å†…å®¹", zap.String("æ–‡æœ¬", trimmedLine))
					continue
				}

				// æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å•ä¸ªå•è¯
				if s.isValidSingleWord(trimmedLine) {
					// æ£€æŸ¥è¿™ä¸ªå•è¯æ–‡æœ¬æ˜¯å¦å·²ç»è¢«å¤„ç†è¿‡ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
					wordTextLower := strings.ToLower(trimmedLine)
					if seenWordTexts[wordTextLower] {
						log.GetLogger().Debug("è·³è¿‡é‡å¤å•è¯",
							zap.String("æ–‡æœ¬", trimmedLine),
							zap.String("æ—¶é—´", blockStartTime+" -> "+blockEndTime))
						continue
					}

					// åˆ›å»ºå•è¯çš„å”¯ä¸€æ ‡è¯†
					wordKey := fmt.Sprintf("%s-%s-%s", trimmedLine, blockStartTime, blockEndTime)
					if !processedWords[wordKey] {
						wordNum++
						word := VttWord{
							Text:  trimmedLine,
							Start: blockStartTime,
							End:   blockEndTime,
							Num:   wordNum,
						}
						words = append(words, word)
						processedWords[wordKey] = true
						seenWordTexts[wordTextLower] = true
						log.GetLogger().Debug("æ·»åŠ å•ä¸ªå•è¯",
							zap.String("æ–‡æœ¬", trimmedLine),
							zap.String("å¼€å§‹", blockStartTime),
							zap.String("ç»“æŸ", blockEndTime))
					}
				} else {
					// è·³è¿‡å®Œæ•´å¥å­æˆ–æ— æ•ˆå†…å®¹
					log.GetLogger().Debug("è·³è¿‡å®Œæ•´å¥å­æˆ–æ— æ•ˆå†…å®¹", zap.String("æ–‡æœ¬", trimmedLine))
				}
			}
		}
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("è¯»å–VTTæ–‡ä»¶å¤±è´¥: %v", err)
	}

	log.GetLogger().Info("VTTå•è¯è§£æå®Œæˆ", zap.Int("æ€»å•è¯æ•°", len(words)))
	return words, nil
}

// cleanVttText æ¸…ç†VTTæ–‡æœ¬ä¸­çš„HTMLå®ä½“å’Œç‰¹æ®Šå­—ç¬¦ï¼ŒåŒ…æ‹¬éŸ³ä¹æ ‡è®°ç­‰
func (s *YouTubeSubtitleService) cleanVttText(text string) string {
	if text == "" {
		return text
	}

	// å…ˆè¿‡æ»¤éŸ³ä¹å’Œå…¶ä»–æç¤ºæ ‡è®°ï¼ˆæ–¹æ‹¬å·å†…å®¹ï¼‰
	// åŒ¹é… [music], [applause], [laughter], [inaudible] ç­‰æ ‡è®°
	bracketRegex := regexp.MustCompile(`\[[^\]]*\]`)
	cleanedText := bracketRegex.ReplaceAllString(text, "")

	// è¿‡æ»¤åœ†æ‹¬å·å†…çš„æç¤ºï¼ˆå¦‚ (music), (applause) ç­‰ï¼‰- æ›´å…¨é¢çš„åŒ¹é…
	parenRegex := regexp.MustCompile(`\([^)]*(?i:music|applause|laughter|laugh|inaudible|mumbling|cheering|whistling|booing|silence|noise|sound|audio)[^)]*\)`)
	cleanedText = parenRegex.ReplaceAllString(cleanedText, "")

	// è¿‡æ»¤éŸ³ä¹ç¬¦å·å’Œè¡¨æƒ…ç¬¦å·
	musicSymbolRegex := regexp.MustCompile(`[â™ªâ™«â™¬â™©ğŸµğŸ¶ğŸ¤ğŸ§ğŸ¼ğŸ¹ğŸ¸ğŸºğŸ»ğŸ¥]`)
	cleanedText = musicSymbolRegex.ReplaceAllString(cleanedText, "")

	// HTMLå®ä½“è§£ç æ˜ å°„
	htmlEntities := map[string]string{
		"&gt;&gt;": ">>", // å¤§äºå·åŒå¼•å·
		"&gt;":     ">",  // å¤§äºå·
		"&lt;&lt;": "<<", // å°äºå·åŒå¼•å·
		"&lt;":     "<",  // å°äºå·
		"&amp;":    "&",  // &ç¬¦å·
		"&quot;":   "\"", // åŒå¼•å·
		"&apos;":   "'",  // å•å¼•å·
		"&nbsp;":   " ",  // ä¸é—´æ–­ç©ºæ ¼
		"&#39;":    "'",  // å•å¼•å·çš„æ•°å­—å®ä½“
		"&#34;":    "\"", // åŒå¼•å·çš„æ•°å­—å®ä½“
		"&#8203;":  "",   // é›¶å®½åº¦ç©ºæ ¼
		"&#8204;":  "",   // é›¶å®½åº¦éè¿æ¥ç¬¦
		"&#8205;":  "",   // é›¶å®½åº¦è¿æ¥ç¬¦
	}

	// æ›¿æ¢HTMLå®ä½“
	for entity, replacement := range htmlEntities {
		cleanedText = strings.ReplaceAll(cleanedText, entity, replacement)
	}

	// ç§»é™¤å¤šä½™çš„ç©ºæ ¼
	cleanedText = strings.TrimSpace(cleanedText)

	// å°†å¤šä¸ªè¿ç»­ç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
	spaceRegex := regexp.MustCompile(`\s+`)
	cleanedText = spaceRegex.ReplaceAllString(cleanedText, " ")

	return cleanedText
}

// isPurePunctuation æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åªåŒ…å«æ ‡ç‚¹ç¬¦å·
func (s *YouTubeSubtitleService) isPurePunctuation(text string) bool {
	if text == "" {
		return false
	}

	// å®šä¹‰æ ‡ç‚¹ç¬¦å·æ­£åˆ™è¡¨è¾¾å¼ï¼ˆåªåŒ…å«æ ‡ç‚¹ç¬¦å·ï¼Œä¸åŒ…å«å­—æ¯å’Œæ•°å­—ï¼‰
	punctOnlyRegex := regexp.MustCompile(`^[^\p{L}\p{N}]+$`)
	return punctOnlyRegex.MatchString(text)
}

// isAudioCue æ£€æŸ¥æ˜¯å¦ä¸ºéŸ³é¢‘æç¤ºè¯ï¼ˆå¦‚musicç­‰ï¼‰
func (s *YouTubeSubtitleService) isAudioCue(text string) bool {
	if text == "" {
		return false
	}

	// å°†æ–‡æœ¬è½¬ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
	lowerText := strings.ToLower(text)

	// ç²¾ç¡®åŒ¹é…çš„éŸ³é¢‘æç¤ºè¯åˆ—è¡¨ï¼ˆå®Œå…¨åŒ¹é…ï¼Œä¸ä½¿ç”¨Containsï¼‰
	exactAudioCues := []string{
		"music", "applause", "laughter", "laugh", "clapping", "clap",
		"cheering", "cheer", "whistling", "whistle", "booing", "boo",
		"silence", "quiet", "noise", "sound", "audio", "inaudible",
		"mumbling", "mumble", "sighing", "sigh", "gasping", "gasp",
		"crying", "cry", "sobbing", "sob", "screaming", "scream",
		"shouting", "shout", "yelling", "yell", "singing", "sing",
		"humming", "hum", "buzzing", "buzz", "ringing", "ring",
		"beeping", "beep", "clicking", "click", "ticking", "tick",
		"background", "bgm", "sfx", "fx", "effect", "effects",
	}

	// æ£€æŸ¥æ˜¯å¦å®Œå…¨åŒ¹é…ä»»ä½•éŸ³é¢‘æç¤ºè¯
	for _, cue := range exactAudioCues {
		if lowerText == cue {
			return true
		}
	}

	// æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹æ®Šå­—ç¬¦æ¨¡å¼ï¼ˆå¦‚â™ª, â™«, â™¬ç­‰éŸ³ä¹ç¬¦å·ï¼‰
	musicSymbolRegex := regexp.MustCompile(`[â™ªâ™«â™¬â™©ğŸµğŸ¶]`)
	if musicSymbolRegex.MatchString(text) {
		return true
	}

	return false
}

// isLikelyRepeatContent æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤çš„å†…å®¹è¡Œï¼ˆé€šå¸¸æ˜¯å®Œæ•´å¥å­ï¼‰
func (s *YouTubeSubtitleService) isLikelyRepeatContent(text string) bool {
	if text == "" {
		return false
	}

	// å¦‚æœåŒ…å«å¤šä¸ªå•è¯ï¼ˆæœ‰ç©ºæ ¼ï¼‰ï¼Œå¾ˆå¯èƒ½æ˜¯é‡å¤çš„å®Œæ•´å¥å­
	if strings.Contains(text, " ") {
		return true
	}

	// å¦‚æœæ–‡æœ¬å¾ˆé•¿ï¼ˆè¶…è¿‡20ä¸ªå­—ç¬¦ï¼‰ï¼Œä¹Ÿå¯èƒ½æ˜¯é‡å¤å†…å®¹
	if len(text) > 20 {
		return true
	}

	return false
}

// isValidSingleWord æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å•ä¸ªå•è¯
func (s *YouTubeSubtitleService) isValidSingleWord(text string) bool {
	if text == "" {
		return false
	}

	// ä¸èƒ½åŒ…å«ç©ºæ ¼ï¼ˆå•ä¸ªå•è¯ï¼‰
	if strings.Contains(text, " ") {
		return false
	}

	// æ£€æŸ¥æ˜¯å¦ä¸ºéŸ³ä¹æˆ–å…¶ä»–æç¤ºæ ‡è®°
	if s.isAudioCue(text) {
		return false
	}

	// ä¸èƒ½åªæ˜¯æ ‡ç‚¹ç¬¦å·
	if s.isPurePunctuation(text) {
		return false
	}

	// é•¿åº¦éœ€è¦åˆç†ï¼ˆ1-15ä¸ªå­—ç¬¦ï¼‰
	if len(text) < 1 || len(text) > 15 {
		return false
	}

	return true
}

// parseWordsWithTimestamps è§£æåŒ…å«æ—¶é—´æˆ³çš„å†…å®¹è¡Œï¼Œä¿æŒæ ‡ç‚¹ç¬¦å·ä¸å•è¯çš„å®Œæ•´æ€§
func (s *YouTubeSubtitleService) parseWordsWithTimestamps(line, blockStart, blockEnd string, wordNum *int) []VttWord {
	var words []VttWord

	// åŒ¹é…å•è¯çº§æ—¶é—´æˆ³
	wordTimeRegex := regexp.MustCompile(`<(\d{2}:\d{2}:\d{2}\.\d{3})>`)

	// æŒ‰æ—¶é—´æˆ³åˆ†å‰²æ–‡æœ¬
	timeMatches := wordTimeRegex.FindAllStringSubmatch(line, -1)
	textParts := wordTimeRegex.Split(line, -1)

	log.GetLogger().Debug("è§£æè¡Œå†…å®¹",
		zap.String("åŸå§‹è¡Œ", line),
		zap.Int("æ—¶é—´æˆ³æ•°é‡", len(timeMatches)),
		zap.Int("æ–‡æœ¬ç‰‡æ®µæ•°é‡", len(textParts)))

	// å¤„ç†ç¬¬ä¸€ä¸ªæ–‡æœ¬ç‰‡æ®µï¼ˆå¼€å§‹åˆ°ç¬¬ä¸€ä¸ªæ—¶é—´æˆ³ï¼‰
	if len(textParts) > 0 && strings.TrimSpace(textParts[0]) != "" {
		firstWordText := strings.TrimSpace(textParts[0])
		var endTime string
		if len(timeMatches) > 0 {
			endTime = timeMatches[0][1]
		} else {
			endTime = blockEnd
		}

		// åˆ†å‰²æˆå•è¯ä½†ä¿æŒæ ‡ç‚¹ç¬¦å·
		wordsInPart := s.splitIntoWordsKeepPunctuation(firstWordText)
		for _, wordText := range wordsInPart {
			words = append(words, VttWord{
				Text:  wordText,
				Start: blockStart,
				End:   endTime,
				Num:   *wordNum,
			})
			(*wordNum)++
		}
	}

	// å¤„ç†å‰©ä½™çš„æ–‡æœ¬ç‰‡æ®µ
	for i := 1; i < len(textParts); i++ {
		textPart := strings.TrimSpace(textParts[i])
		if textPart == "" {
			continue
		}

		// ç¡®å®šå¼€å§‹æ—¶é—´
		startTime := timeMatches[i-1][1]

		// ç¡®å®šç»“æŸæ—¶é—´
		var endTime string
		if i < len(timeMatches) {
			endTime = timeMatches[i][1]
		} else {
			endTime = blockEnd
		}

		// åˆ†å‰²æˆå•è¯ä½†ä¿æŒæ ‡ç‚¹ç¬¦å·
		wordsInPart := s.splitIntoWordsKeepPunctuation(textPart)
		for _, wordText := range wordsInPart {
			words = append(words, VttWord{
				Text:  wordText,
				Start: startTime,
				End:   endTime,
				Num:   *wordNum,
			})
			(*wordNum)++
		}
	}

	return words
}

// splitIntoWordsKeepPunctuation å°†æ–‡æœ¬åˆ†å‰²æˆå•è¯ï¼Œä½†ä¿æŒæ ‡ç‚¹ç¬¦å·ä¸å•è¯çš„å®Œæ•´æ€§
func (s *YouTubeSubtitleService) splitIntoWordsKeepPunctuation(text string) []string {
	if strings.TrimSpace(text) == "" {
		return nil
	}

	// ä½¿ç”¨ç©ºæ ¼åˆ†å‰²ï¼Œä½†ä¿æŒæ ‡ç‚¹ç¬¦å·ä¸å•è¯åœ¨ä¸€èµ·
	rawWords := strings.Fields(text)
	var result []string

	for _, word := range rawWords {
		// æ¸…ç†æ¯ä¸ªå•è¯ä¸­çš„ç‰¹æ®Šå­—ç¬¦
		cleanedWord := s.cleanVttText(word)
		if strings.TrimSpace(cleanedWord) != "" {
			result = append(result, cleanedWord)
		}
	}

	return result
}

// ConvertVttToSrt å°†VTTè½¬æ¢ä¸ºSRTæ ¼å¼
func (s *YouTubeSubtitleService) ConvertVttToSrt(req *YoutubeSubtitleReq, srtFile string) error {
	// æ£€æŸ¥VttFileå­—æ®µæ˜¯å¦å­˜åœ¨
	vttFilePath := req.VttFile
	if vttFilePath == "" {
		// å¦‚æœVttFileä¸ºç©ºï¼Œå°è¯•åœ¨ä»»åŠ¡ç›®å½•ä¸­æŸ¥æ‰¾VTTæ–‡ä»¶
		log.GetLogger().Warn("VTT file path is empty, trying to find VTT file in task directory",
			zap.String("taskBasePath", req.TaskBasePath))

		foundVttFile, err := s.findVttFileInDirectory(req.TaskBasePath)
		if err != nil {
			return fmt.Errorf("VTT file path is empty and failed to find VTT file in directory: %w", err)
		}
		vttFilePath = foundVttFile
		log.GetLogger().Info("Found VTT file in task directory", zap.String("vttFile", vttFilePath))
	}

	// ä½¿ç”¨æ–°çš„ExtractWordsFromVttå‡½æ•°è·å–VttWord
	vttWords, err := s.ExtractWordsFromVtt(vttFilePath)
	if err != nil {
		return fmt.Errorf("failed to extract VTT words: %w", err)
	}

	// å°†VttWordè½¬æ¢ä¸ºSRTæ ¼å¼
	return s.writeVttWordsToSrt(vttWords, srtFile, req)
}

// findVttFileInDirectory åœ¨æŒ‡å®šç›®å½•ä¸­æŸ¥æ‰¾VTTæ–‡ä»¶
func (s *YouTubeSubtitleService) findVttFileInDirectory(dir string) (string, error) {
	entries, err := os.ReadDir(dir)
	if err != nil {
		return "", fmt.Errorf("failed to read directory %s: %w", dir, err)
	}

	for _, entry := range entries {
		if entry.IsDir() {
			continue
		}

		fileName := entry.Name()
		if strings.HasSuffix(strings.ToLower(fileName), ".vtt") {
			fullPath := filepath.Join(dir, fileName)
			log.GetLogger().Info("Found VTT file", zap.String("file", fullPath))
			return fullPath, nil
		}
	}

	return "", fmt.Errorf("no VTT file found in directory: %s", dir)
}

// writeVttWordsToSrt å°†VttWordæ•°ç»„å†™å…¥SRTæ–‡ä»¶ï¼Œæ”¯æŒç¿»è¯‘å’Œæ—¶é—´æˆ³ç”Ÿæˆ
func (s *YouTubeSubtitleService) writeVttWordsToSrt(vttWords []VttWord, srtFile string, req *YoutubeSubtitleReq) error {
	if len(vttWords) == 0 {
		return fmt.Errorf("no VTT words to write")
	}

	// åˆå§‹è¿›åº¦åŸºå‡†ï¼ˆä»å½“å‰è¿›åº¦å¼€å§‹ï¼Œåˆ°90%ç»“æŸï¼‰
	baseProgress := uint8(10) // å‡è®¾å‡½æ•°å¼€å§‹æ—¶å·²æœ‰10%è¿›åº¦
	if req.TaskPtr != nil && req.TaskPtr.ProcessPct > 0 {
		baseProgress = req.TaskPtr.ProcessPct
	}
	targetProgress := uint8(90) // å‡½æ•°å®Œæˆæ—¶çš„ç›®æ ‡è¿›åº¦

	// æ­¥éª¤1: æ ¹æ®æ ‡ç‚¹ç¬¦å·å°†å•è¯æ•´ç†æˆå®Œæ•´çš„å¥å­ (çº¦å æ€»è¿›åº¦çš„10%)
	sentences := s.groupWordsIntoSentences(vttWords)
	if len(sentences) == 0 {
		return fmt.Errorf("no sentences formed from VTT words")
	}

	// æ›´æ–°è¿›åº¦åˆ°15%
	if req.TaskPtr != nil {
		req.TaskPtr.ProcessPct = baseProgress + uint8(float64(targetProgress-baseProgress)*0.1)
		log.GetLogger().Info("Progress updated after grouping sentences",
			zap.Uint8("progress", req.TaskPtr.ProcessPct))
	}

	log.GetLogger().Info("Grouped VTT words into sentences", zap.Int("å¥å­æ•°", len(sentences)))

	// åˆ›å»ºåˆå§‹çš„SrtBlockåˆ—è¡¨
	srtBlocks := make([]*util.SrtBlock, 0, 2*len(sentences))

	// ä½¿ç”¨å¹¶å‘ç¿»è¯‘ï¼ŒåŒæ—¶ä¿è¯é¡ºåº
	type translationResult struct {
		index  int
		blocks []*util.SrtBlock
		err    error
	}

	// åˆ›å»ºç»“æœé€šé“å’Œgoroutineæ•°é‡æ§åˆ¶
	resultCh := make(chan translationResult, len(sentences))
	maxConcurrency := 5 // é™åˆ¶å¹¶å‘æ•°é‡ï¼Œé¿å…è¯·æ±‚è¿‡å¤š
	semaphore := make(chan struct{}, maxConcurrency)

	// å¯åŠ¨å¹¶å‘ç¿»è¯‘
	for idx, sentence := range sentences {
		go func(index int, sent Sentence) {
			// è·å–ä¿¡å·é‡
			semaphore <- struct{}{}
			defer func() { <-semaphore }()

			translatedBlocks, err := s.translator.SplitTextAndTranslate(sent.Text, types.StandardLanguageCode(req.OriginLanguage), types.StandardLanguageCode(req.TargetLanguage))
			if err != nil {
				log.GetLogger().Warn("Translation failed, using original text",
					zap.Int("index", index),
					zap.Error(err))
				resultCh <- translationResult{index: index, blocks: nil, err: err}
				return
			}

			// æ„å»ºä¸´æ—¶SrtBlock
			notsSrtBlock := make([]*util.SrtBlock, 0, len(translatedBlocks))
			for _, block := range translatedBlocks {
				notsSrtBlock = append(notsSrtBlock, &util.SrtBlock{
					OriginLanguageSentence: block.OriginText,
					TargetLanguageSentence: block.TranslatedText,
				})
			}

			// ç”Ÿæˆæ—¶é—´æˆ³
			updatedBlocks, err := s.timestampGenerator.GenerateTimestamps(
				notsSrtBlock,
				s.convertVttWordsToTypesWords(sent.Words),
				types.StandardLanguageCode("base"), // é»˜è®¤ä½¿ç”¨baseè¯­è¨€ç±»å‹
				0.0,                                // æ—¶é—´åç§»
			)
			if err != nil {
				log.GetLogger().Warn("Timestamp generation failed",
					zap.Int("index", index),
					zap.Error(err))
				updatedBlocks = notsSrtBlock // ä½¿ç”¨æœªç”Ÿæˆæ—¶é—´æˆ³çš„å—
			}

			resultCh <- translationResult{index: index, blocks: updatedBlocks, err: nil}
		}(idx, sentence)
	}

	// æ”¶é›†ç»“æœï¼ŒæŒ‰é¡ºåºæ’åˆ—ï¼Œå®æ—¶æ›´æ–°è¿›åº¦ (å æ€»è¿›åº¦çš„70%)
	results := make(map[int][]*util.SrtBlock)
	completedTasks := 0
	translationProgressBase := baseProgress + uint8(float64(targetProgress-baseProgress)*0.1) // 15%
	translationProgressRange := uint8(float64(targetProgress-baseProgress) * 0.7)             // 70%çš„è¿›åº¦èŒƒå›´

	for i := 0; i < len(sentences); i++ {
		result := <-resultCh
		completedTasks++

		if result.err == nil {
			results[result.index] = result.blocks
		}

		// å®æ—¶æ›´æ–°ç¿»è¯‘è¿›åº¦
		if req.TaskPtr != nil {
			currentTranslationProgress := float64(completedTasks) / float64(len(sentences))
			req.TaskPtr.ProcessPct = translationProgressBase + uint8(float64(translationProgressRange)*currentTranslationProgress)

			// æ¯å®Œæˆ5ä¸ªæˆ–å®Œæˆæ‰€æœ‰ä»»åŠ¡æ—¶è®°å½•æ—¥å¿—
			if completedTasks%5 == 0 || completedTasks == len(sentences) {
				log.GetLogger().Info("Translation progress updated",
					zap.Int("completed", completedTasks),
					zap.Int("total", len(sentences)),
					zap.Uint8("progress", req.TaskPtr.ProcessPct))
			}
		}
	}

	// æŒ‰é¡ºåºæ·»åŠ åˆ°æœ€ç»ˆçš„srtBlocks (å æ€»è¿›åº¦çš„10%)
	var blockIndex int
	for i := 0; i < len(sentences); i++ {
		if blocks, exists := results[i]; exists {
			for _, block := range blocks {
				srtBlocks = append(srtBlocks, &util.SrtBlock{
					Index:                  blockIndex + 1,
					Timestamp:              block.Timestamp,
					OriginLanguageSentence: block.OriginLanguageSentence,
					TargetLanguageSentence: block.TargetLanguageSentence,
				})
				blockIndex++
			}
		}
	}

	// æ›´æ–°è¿›åº¦åˆ°85%ï¼ˆç»“æœæ•´ç†å®Œæˆï¼‰
	if req.TaskPtr != nil {
		req.TaskPtr.ProcessPct = baseProgress + uint8(float64(targetProgress-baseProgress)*0.85)
		log.GetLogger().Info("Progress updated after organizing results",
			zap.Uint8("progress", req.TaskPtr.ProcessPct))
	}

	// æ­¥éª¤6: å†™å…¥æ­£å¸¸çš„SRTæ–‡ä»¶
	err := s.writeSrtBlocksToFile(srtBlocks, srtFile)
	if err != nil {
		return err
	}

	// æ›´æ–°è¿›åº¦åˆ°88%ï¼ˆæ­£å¸¸SRTæ–‡ä»¶å†™å…¥å®Œæˆï¼‰
	if req.TaskPtr != nil {
		req.TaskPtr.ProcessPct = baseProgress + uint8(float64(targetProgress-baseProgress)*0.88)
		log.GetLogger().Info("Progress updated after writing SRT file",
			zap.Uint8("progress", req.TaskPtr.ProcessPct))
	}

	// æ­¥éª¤7: ç”ŸæˆçŸ­å­—å¹•æ–‡ä»¶
	shortSrtFile := filepath.Join(filepath.Dir(srtFile), types.SubtitleTaskShortOriginMixedSrtFileName)
	err = s.writeShortMixedSrtFile(srtBlocks, shortSrtFile, sentences)
	if err != nil {
		return err
	}

	// æœ€ç»ˆæ›´æ–°è¿›åº¦åˆ°90%ï¼ˆæ‰€æœ‰æ“ä½œå®Œæˆï¼‰
	if req.TaskPtr != nil {
		req.TaskPtr.ProcessPct = targetProgress
		log.GetLogger().Info("writeVttWordsToSrt completed",
			zap.Uint8("final_progress", req.TaskPtr.ProcessPct),
			zap.Int("total_srt_blocks", len(srtBlocks)))
	}

	return nil
}

// Sentence è¡¨ç¤ºä¸€ä¸ªå®Œæ•´çš„å¥å­åŠå…¶æ—¶é—´ä¿¡æ¯
type Sentence struct {
	Text      string    // å¥å­æ–‡æœ¬
	Words     []VttWord // ç»„æˆå¥å­çš„å•è¯
	StartTime string    // å¥å­å¼€å§‹æ—¶é—´
	EndTime   string    // å¥å­ç»“æŸæ—¶é—´
}

// groupWordsIntoSentences æ ¹æ®æ ‡ç‚¹ç¬¦å·å°†å•è¯åˆ†ç»„æˆå®Œæ•´çš„å¥å­
func (s *YouTubeSubtitleService) groupWordsIntoSentences(words []VttWord) []Sentence {
	if len(words) == 0 {
		return nil
	}

	// ç¬¬ä¸€æ­¥ï¼šæŒ‰æ•´å¥æ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼ˆå¥å·ã€é—®å·ã€æ„Ÿå¹å·ï¼‰
	primarySentences := s.splitByPrimarySentencePunctuation(words)

	// ç¬¬äºŒæ­¥ï¼šå¯¹è¶…é•¿çš„å¥å­æŒ‰é€—å·ã€åˆ†å·ç­‰è¿›è¡ŒäºŒæ¬¡åˆ†å‰²
	var finalSentences []Sentence
	for _, sentence := range primarySentences {
		if util.CountEffectiveChars(sentence.Text) > config.Conf.App.MaxSentenceLength {
			// è¶…é•¿å¥å­ï¼ŒæŒ‰é€—å·ç­‰è¿›è¡ŒäºŒæ¬¡åˆ†å‰²
			secondarySentences := s.splitBySecondarySentencePunctuation(sentence.Words)
			finalSentences = append(finalSentences, secondarySentences...)
		} else {
			// å¥å­é•¿åº¦åˆé€‚ï¼Œç›´æ¥ä¿ç•™
			finalSentences = append(finalSentences, sentence)
		}
	}

	log.GetLogger().Debug("Grouped words into sentences",
		zap.Int("æ€»å•è¯æ•°", len(words)),
		zap.Int("ä¸€çº§åˆ†å‰²å¥å­æ•°", len(primarySentences)),
		zap.Int("æœ€ç»ˆå¥å­æ•°", len(finalSentences)))

	return finalSentences
}

// GroupWordsIntoSentencesPublic å…¬å¼€çš„åˆ†ç»„æ–¹æ³•ï¼Œç”¨äºæµ‹è¯•
func (s *YouTubeSubtitleService) GroupWordsIntoSentencesPublic(words []VttWord) []Sentence {
	return s.groupWordsIntoSentences(words)
}

// ExtractWordsFromVttPublic å…¬å¼€çš„VTTæå–æ–¹æ³•ï¼Œç”¨äºæµ‹è¯•
func (s *YouTubeSubtitleService) ExtractWordsFromVttPublic(vttFile string) ([]VttWord, error) {
	return s.ExtractWordsFromVtt(vttFile)
}

// SplitBySecondarySentencePunctuationPublic å…¬å¼€çš„äºŒæ¬¡åˆ†å‰²æ–¹æ³•ï¼Œç”¨äºæµ‹è¯•
func (s *YouTubeSubtitleService) SplitBySecondarySentencePunctuationPublic(words []VttWord) []Sentence {
	return s.splitBySecondarySentencePunctuation(words)
}

// CleanVttTextPublic å…¬å¼€çš„æ–‡æœ¬æ¸…ç†æ–¹æ³•ï¼Œç”¨äºæµ‹è¯•
func (s *YouTubeSubtitleService) CleanVttTextPublic(text string) string {
	return s.cleanVttText(text)
}

// IsValidSingleWordPublic å…¬å¼€çš„å•è¯éªŒè¯æ–¹æ³•ï¼Œç”¨äºæµ‹è¯•
func (s *YouTubeSubtitleService) IsValidSingleWordPublic(text string) bool {
	return s.isValidSingleWord(text)
}

// IsAudioCuePublic å…¬å¼€çš„éŸ³é¢‘æç¤ºæ£€æµ‹æ–¹æ³•ï¼Œç”¨äºæµ‹è¯•
func (s *YouTubeSubtitleService) IsAudioCuePublic(text string) bool {
	return s.isAudioCue(text)
}

// endsWithSentencePunctuation æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä»¥å¥å­ç»“æŸæ ‡ç‚¹ç¬¦å·ç»“å°¾
func (s *YouTubeSubtitleService) endsWithSentencePunctuation(text string, punctuation []rune) bool {
	if text == "" {
		return false
	}

	textRunes := []rune(text)
	lastRune := textRunes[len(textRunes)-1]

	for _, punct := range punctuation {
		if lastRune == punct {
			return true
		}
	}
	return false
}

// splitByPrimarySentencePunctuation æŒ‰æ•´å¥æ ‡ç‚¹ç¬¦å·ï¼ˆå¥å·ã€é—®å·ã€æ„Ÿå¹å·ï¼‰åˆ†å‰²
func (s *YouTubeSubtitleService) splitByPrimarySentencePunctuation(words []VttWord) []Sentence {
	if len(words) == 0 {
		return nil
	}

	var sentences []Sentence
	var currentWords []VttWord
	primaryEndPunctuation := []rune{'.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ'}

	for _, word := range words {
		currentWords = append(currentWords, word)

		// æ£€æŸ¥å•è¯æ˜¯å¦ä»¥æ•´å¥ç»“æŸæ ‡ç‚¹ç¬¦å·ç»“å°¾
		if s.endsWithSentencePunctuation(word.Text, primaryEndPunctuation) {
			if len(currentWords) > 0 {
				sentence := s.createSentenceFromWords(currentWords)
				sentences = append(sentences, sentence)
				currentWords = []VttWord{} // é‡ç½®
			}
		}
	}

	// å¤„ç†æœ€åä¸€ç»„å•è¯ï¼ˆå¦‚æœæ²¡æœ‰ä»¥æ ‡ç‚¹ç»“å°¾ï¼‰
	if len(currentWords) > 0 {
		sentence := s.createSentenceFromWords(currentWords)
		sentences = append(sentences, sentence)
	}

	return sentences
}

// splitBySecondarySentencePunctuation æŒ‰é€—å·ã€åˆ†å·ç­‰æ–­å¥æ ‡ç‚¹ç¬¦å·åˆ†å‰²
func (s *YouTubeSubtitleService) splitBySecondarySentencePunctuation(words []VttWord) []Sentence {
	if len(words) == 0 {
		return nil
	}

	var sentences []Sentence
	var currentWords []VttWord
	secondaryEndPunctuation := []rune{',', ';', 'ï¼Œ', 'ï¼›'} // ä¸­è‹±æ–‡é€—å·å’Œåˆ†å·
	foundPunctuation := false                             // è·Ÿè¸ªæ˜¯å¦æ‰¾åˆ°äº†æ ‡ç‚¹ç¬¦å·

	for _, word := range words {
		currentWords = append(currentWords, word)

		// æ£€æŸ¥å•è¯æ˜¯å¦ä»¥é€—å·æˆ–åˆ†å·ç»“å°¾
		if s.endsWithSentencePunctuation(word.Text, secondaryEndPunctuation) {
			foundPunctuation = true
			if len(currentWords) > 0 {
				sentence := s.createSentenceFromWords(currentWords)
				sentences = append(sentences, sentence)
				currentWords = []VttWord{} // é‡ç½®
			}
		}
	}

	// å¤„ç†æœ€åä¸€ç»„å•è¯
	if len(currentWords) > 0 {
		sentence := s.createSentenceFromWords(currentWords)
		sentences = append(sentences, sentence)
	}

	// å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯åˆ†å‰²çš„æ ‡ç‚¹ç¬¦å·ï¼Œä½¿ç”¨æ™ºèƒ½åˆ†å¥ç­–ç•¥
	if !foundPunctuation {
		log.GetLogger().Info("No punctuation found, using smart sentence splitting",
			zap.Int("total_words", len(words)))
		return s.splitBySmartRules(words)
	}

	// å¦‚æœæ‰¾åˆ°æ ‡ç‚¹ç¬¦å·ä½†å¥å­ä»ç„¶è¿‡é•¿ï¼Œä¹Ÿä½¿ç”¨æ™ºèƒ½åˆ†å¥ä½œä¸ºè¡¥å……
	for _, sentence := range sentences {
		if util.CountEffectiveChars(sentence.Text) > config.Conf.App.MaxSentenceLength {
			log.GetLogger().Info("Found long sentence even after punctuation split, using smart splitting",
				zap.Int("sentence_length", util.CountEffectiveChars(sentence.Text)),
				zap.Int("max_length", config.Conf.App.MaxSentenceLength))
			return s.splitBySmartRules(words)
		}
	}

	return sentences
}

// createSentenceFromWords ä»å•è¯åˆ—è¡¨åˆ›å»ºå¥å­
func (s *YouTubeSubtitleService) createSentenceFromWords(words []VttWord) Sentence {
	if len(words) == 0 {
		return Sentence{}
	}

	var textParts []string
	for _, word := range words {
		textParts = append(textParts, word.Text)
	}

	return Sentence{
		Text:      strings.Join(textParts, " "),
		Words:     words,
		StartTime: words[0].Start,
		EndTime:   words[len(words)-1].End,
	}
}

// convertVttWordsToTypesWords å°†VttWordè½¬æ¢ä¸ºtypes.Wordä¾›æ—¶é—´æˆ³ç”Ÿæˆå™¨ä½¿ç”¨
func (s *YouTubeSubtitleService) convertVttWordsToTypesWords(vttWords []VttWord) []types.Word {
	var typesWords []types.Word

	for _, vttWord := range vttWords {
		// å°†å­—ç¬¦ä¸²æ—¶é—´æˆ³è½¬æ¢ä¸ºfloat64
		startTime, _ := s.parseVttTime(vttWord.Start)
		endTime, _ := s.parseVttTime(vttWord.End)

		typesWords = append(typesWords, types.Word{
			Text:  vttWord.Text,
			Start: startTime,
			End:   endTime,
			Num:   vttWord.Num,
		})
	}

	return typesWords
}

// writeSrtBlocksToFile å°†SrtBlockæ•°ç»„å†™å…¥æ–‡ä»¶
func (s *YouTubeSubtitleService) writeSrtBlocksToFile(blocks []*util.SrtBlock, srtFile string) error {
	file, err := os.Create(srtFile)
	if err != nil {
		return fmt.Errorf("failed to create SRT file: %w", err)
	}
	defer file.Close()

	for _, block := range blocks {
		// å†™å…¥åºå·
		_, err = file.WriteString(fmt.Sprintf("%d\n", block.Index))
		if err != nil {
			return err
		}

		// å†™å…¥æ—¶é—´æˆ³
		_, err = file.WriteString(block.Timestamp + "\n")
		if err != nil {
			return err
		}

		// å†™å…¥æ–‡æœ¬å†…å®¹ - åŒè¯­æ˜¾ç¤ºï¼šç›®æ ‡è¯­è¨€åœ¨ä¸Šï¼ŒåŸè¯­è¨€åœ¨ä¸‹
		var textContent strings.Builder
		if block.TargetLanguageSentence != "" {
			textContent.WriteString(block.TargetLanguageSentence)
			if block.OriginLanguageSentence != "" {
				textContent.WriteString("\n")
				textContent.WriteString(block.OriginLanguageSentence)
			}
		} else if block.OriginLanguageSentence != "" {
			// å¦‚æœæ²¡æœ‰ç¿»è¯‘ï¼Œåªæ˜¾ç¤ºåŸè¯­è¨€
			textContent.WriteString(block.OriginLanguageSentence)
		}

		if textContent.Len() > 0 {
			_, err = file.WriteString(textContent.String() + "\n\n")
			if err != nil {
				return err
			}
		}
	}

	log.GetLogger().Info("SRT file written successfully",
		zap.String("æ–‡ä»¶", srtFile),
		zap.Int("å—æ•°", len(blocks)))

	return nil
}

// writeShortMixedSrtFile ç”ŸæˆçŸ­å­—å¹•æ–‡ä»¶ï¼ŒåŸºäºå·²æ‹†åˆ†çš„é•¿å­—å¹•SRTå—
func (s *YouTubeSubtitleService) writeShortMixedSrtFile(srtBlocks []*util.SrtBlock, shortSrtFile string, sentences []Sentence) error {
	file, err := os.Create(shortSrtFile)
	if err != nil {
		return fmt.Errorf("failed to create short SRT file: %w", err)
	}
	defer file.Close()

	blockIndex := 1
	wordsPerSegment := 6 // æ¯ä¸ªçŸ­å­—å¹•æ˜¾ç¤ºçš„å•è¯æ•°é‡

	// æ·»åŠ usedIndicesè·Ÿè¸ªå·²ä½¿ç”¨çš„VTTå•è¯
	allWords := s.getAllWordsFromSentences(sentences)
	usedIndices := make(map[int]bool)

	for _, srtBlock := range srtBlocks {
		// å…ˆå†™å…¥å®Œæ•´çš„ç›®æ ‡è¯­è¨€å­—å¹•å—ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰
		if srtBlock.TargetLanguageSentence != "" {
			_, err = file.WriteString(fmt.Sprintf("%d\n", blockIndex))
			if err != nil {
				return err
			}

			_, err = file.WriteString(srtBlock.Timestamp + "\n")
			if err != nil {
				return err
			}

			_, err = file.WriteString(srtBlock.TargetLanguageSentence + "\n\n")
			if err != nil {
				return err
			}
			blockIndex++
		}

		// å¤„ç†å¯¹åº”çš„åŸå§‹è¯­è¨€ï¼ˆè‹±æ–‡ï¼‰ï¼ŒæŒ‰å•è¯æ‹†åˆ†
		if srtBlock.OriginLanguageSentence != "" {
			// å°†åŸå§‹è¯­è¨€å¥å­æŒ‰ç©ºæ ¼åˆ†å‰²æˆå•è¯ï¼Œå¹¶æ¸…ç†å¤šä½™çš„å¼•å·
			originText := strings.TrimSpace(srtBlock.OriginLanguageSentence)
			// æ¸…ç†å¼€å¤´å’Œç»“å°¾çš„å¤šä½™å¼•å·
			originText = strings.Trim(originText, `"'`)
			words := strings.Fields(originText)

			// æ‰¾åˆ°æ•´ä¸ªSRTå—å¯¹åº”çš„VttWordåºåˆ—ï¼Œä½¿ç”¨è·Ÿè¸ªç‰ˆæœ¬é¿å…é‡å¤åŒ¹é…
			correspondingVttWords := s.findCorrespondingWordsWithTracking(srtBlock, allWords, usedIndices)

			log.GetLogger().Debug("Processing SRT block for short subtitles",
				zap.String("originText", originText),
				zap.Int("wordsCount", len(words)),
				zap.Int("correspondingVttWordsCount", len(correspondingVttWords)))

			// æŒ‰æŒ‡å®šæ•°é‡æ‹†åˆ†å•è¯
			for wordStart := 0; wordStart < len(words); wordStart += wordsPerSegment {
				wordEnd := wordStart + wordsPerSegment
				if wordEnd > len(words) {
					wordEnd = len(words)
				}

				segmentWords := words[wordStart:wordEnd]
				if len(segmentWords) == 0 {
					continue
				}

				segmentText := strings.Join(segmentWords, " ")

				// è®¡ç®—è¿™ä¸ªç‰‡æ®µå¯¹åº”çš„VTTå•è¯æ—¶é—´æˆ³
				var srtTimestamp string
				if len(correspondingVttWords) > 0 && len(words) > 0 {
					// è®¡ç®—ç‰‡æ®µåœ¨æ•´ä¸ªSRTå—ä¸­çš„ç›¸å¯¹ä½ç½®
					startRatio := float64(wordStart) / float64(len(words))
					endRatio := float64(wordEnd) / float64(len(words))

					// æ˜ å°„åˆ°correspondingVttWordsä¸­çš„ä½ç½®
					vttStartIdx := int(startRatio * float64(len(correspondingVttWords)))
					vttEndIdx := int(endRatio * float64(len(correspondingVttWords)))

					// ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
					if vttStartIdx >= len(correspondingVttWords) {
						vttStartIdx = len(correspondingVttWords) - 1
					}
					if vttEndIdx > len(correspondingVttWords) {
						vttEndIdx = len(correspondingVttWords)
					}
					if vttEndIdx <= vttStartIdx {
						vttEndIdx = vttStartIdx + 1
					}

					// è·å–æ—¶é—´æˆ³
					startTime := correspondingVttWords[vttStartIdx].Start
					endTime := correspondingVttWords[vttEndIdx-1].End

					log.GetLogger().Debug("Calculated segment timestamps",
						zap.String("segmentText", segmentText),
						zap.Int("vttStartIdx", vttStartIdx),
						zap.Int("vttEndIdx", vttEndIdx),
						zap.String("startTime", startTime),
						zap.String("endTime", endTime))

					var err error
					srtTimestamp, err = s.convertToSrtTimestamp(startTime, endTime)
					if err != nil {
						srtTimestamp = srtBlock.Timestamp
						log.GetLogger().Warn("Failed to convert timestamp, using SRT block timestamp", zap.Error(err))
					}
				} else {
					// Fallbackåˆ°SRTå—æ—¶é—´æˆ³
					srtTimestamp = srtBlock.Timestamp
					log.GetLogger().Warn("No corresponding VTT words found, using SRT block timestamp",
						zap.Int("correspondingVttWordsCount", len(correspondingVttWords)),
						zap.Int("wordsCount", len(words)))
				}

				// å†™å…¥æºè¯­è¨€ç‰‡æ®µ
				_, err = file.WriteString(fmt.Sprintf("%d\n", blockIndex))
				if err != nil {
					return err
				}

				_, err = file.WriteString(srtTimestamp + "\n")
				if err != nil {
					return err
				}

				_, err = file.WriteString(segmentText + "\n\n")
				if err != nil {
					return err
				}
				blockIndex++
			}
		}
	}

	log.GetLogger().Info("Short mixed SRT file written successfully",
		zap.String("æ–‡ä»¶", shortSrtFile),
		zap.Int("æ€»å—æ•°", blockIndex-1))

	return nil
}

// findVttWordsForText æ ¹æ®æ–‡æœ¬å†…å®¹åœ¨å¥å­ä¸­æ‰¾åˆ°å¯¹åº”çš„VttWord
func (s *YouTubeSubtitleService) findVttWordsForText(text string, sentences []Sentence) []VttWord {
	textWords := strings.Fields(strings.TrimSpace(text))
	if len(textWords) == 0 {
		return []VttWord{}
	}

	// åœ¨æ‰€æœ‰å¥å­ä¸­å¯»æ‰¾åŒ¹é…çš„å•è¯åºåˆ—
	for _, sentence := range sentences {
		if len(sentence.Words) < len(textWords) {
			continue
		}

		// å°è¯•åœ¨è¿™ä¸ªå¥å­ä¸­æ‰¾åˆ°åŒ¹é…çš„å•è¯åºåˆ—
		for startIdx := 0; startIdx <= len(sentence.Words)-len(textWords); startIdx++ {
			match := true
			for i, expectedWord := range textWords {
				actualWord := strings.TrimSpace(sentence.Words[startIdx+i].Text)
				expectedClean := strings.Trim(expectedWord, ".,!?;:")
				actualClean := strings.Trim(actualWord, ".,!?;:")

				if !strings.EqualFold(expectedClean, actualClean) {
					match = false
					break
				}
			}

			if match {
				return sentence.Words[startIdx : startIdx+len(textWords)]
			}
		}
	}

	return []VttWord{}
}

// getAllWordsFromSentences ä»æ‰€æœ‰å¥å­ä¸­è·å–æ‰€æœ‰å•è¯çš„æ‰å¹³åˆ—è¡¨
func (s *YouTubeSubtitleService) getAllWordsFromSentences(sentences []Sentence) []VttWord {
	var allWords []VttWord
	for _, sentence := range sentences {
		allWords = append(allWords, sentence.Words...)
	}
	return allWords
}

// findCorrespondingWords æ ¹æ®SRTå—çš„åŸå§‹æ–‡æœ¬æ‰¾åˆ°å¯¹åº”çš„åŸå§‹å•è¯
func (s *YouTubeSubtitleService) findCorrespondingWords(srtBlock *util.SrtBlock, allWords []VttWord) []VttWord {
	if srtBlock.OriginLanguageSentence == "" {
		return []VttWord{}
	}

	// åŸºäºæ–‡æœ¬å†…å®¹åŒ¹é…ï¼Œè€Œä¸æ˜¯æ—¶é—´æˆ³åŒ¹é…
	originText := strings.TrimSpace(srtBlock.OriginLanguageSentence)
	// æ¸…ç†å¼€å¤´å’Œç»“å°¾çš„å¼•å·
	originText = strings.Trim(originText, `"'`)

	// å°†åŸå§‹æ–‡æœ¬æŒ‰ç©ºæ ¼åˆ†å‰²æˆå•è¯
	expectedWords := strings.Fields(originText)
	if len(expectedWords) == 0 {
		return []VttWord{}
	}

	log.GetLogger().Debug("Finding corresponding words",
		zap.String("originText", originText),
		zap.Int("expectedWordsCount", len(expectedWords)),
		zap.Int("allWordsCount", len(allWords)))

	// åœ¨æ‰€æœ‰å•è¯ä¸­æŸ¥æ‰¾åŒ¹é…çš„åºåˆ—
	var correspondingWords []VttWord

	for i := 0; i <= len(allWords)-len(expectedWords); i++ {
		// æ£€æŸ¥ä»ä½ç½®iå¼€å§‹æ˜¯å¦åŒ¹é…expectedWordsåºåˆ—
		match := true
		candidateWords := make([]VttWord, len(expectedWords))

		for j, expectedWord := range expectedWords {
			if i+j >= len(allWords) {
				match = false
				break
			}

			actualWord := strings.TrimSpace(allWords[i+j].Text)
			// ç§»é™¤æ ‡ç‚¹ç¬¦å·è¿›è¡Œæ¯”è¾ƒ
			expectedWordClean := strings.Trim(expectedWord, ".,!?;:")
			actualWordClean := strings.Trim(actualWord, ".,!?;:")

			if !strings.EqualFold(expectedWordClean, actualWordClean) {
				match = false
				break
			}
			candidateWords[j] = allWords[i+j]
		}

		if match {
			correspondingWords = candidateWords
			break
		}
	}

	log.GetLogger().Debug("Found corresponding words",
		zap.String("originText", originText),
		zap.Int("foundWords", len(correspondingWords)))

	return correspondingWords
}

// findCorrespondingWordsWithTracking æ ¹æ®SRTå—çš„åŸå§‹æ–‡æœ¬æ‰¾åˆ°å¯¹åº”çš„åŸå§‹å•è¯ï¼Œå¹¶è¿½è¸ªå·²ä½¿ç”¨çš„å•è¯
func (s *YouTubeSubtitleService) findCorrespondingWordsWithTracking(srtBlock *util.SrtBlock, allWords []VttWord, usedIndices map[int]bool) []VttWord {
	if srtBlock.OriginLanguageSentence == "" {
		return []VttWord{}
	}

	// åŸºäºæ–‡æœ¬å†…å®¹åŒ¹é…
	originText := strings.TrimSpace(srtBlock.OriginLanguageSentence)
	expectedWords := strings.Fields(originText)
	if len(expectedWords) == 0 {
		return []VttWord{}
	}

	// åœ¨æ‰€æœ‰å•è¯ä¸­æŸ¥æ‰¾åŒ¹é…çš„åºåˆ—ï¼Œè·³è¿‡å·²ä½¿ç”¨çš„å•è¯
	var correspondingWords []VttWord

	for i := 0; i <= len(allWords)-len(expectedWords); i++ {
		// è·³è¿‡å·²ä½¿ç”¨çš„èµ·å§‹ä½ç½®
		if usedIndices[i] {
			continue
		}

		// æ£€æŸ¥ä»ä½ç½®iå¼€å§‹æ˜¯å¦åŒ¹é…expectedWordsåºåˆ—
		match := true
		candidateWords := make([]VttWord, len(expectedWords))
		candidateIndices := make([]int, len(expectedWords))

		for j, expectedWord := range expectedWords {
			wordIndex := i + j
			if wordIndex >= len(allWords) || usedIndices[wordIndex] {
				match = false
				break
			}

			actualWord := strings.TrimSpace(allWords[wordIndex].Text)
			expectedWordClean := strings.Trim(expectedWord, ".,!?;:")
			actualWordClean := strings.Trim(actualWord, ".,!?;:")

			if !strings.EqualFold(expectedWordClean, actualWordClean) {
				match = false
				break
			}
			candidateWords[j] = allWords[wordIndex]
			candidateIndices[j] = wordIndex
		}

		if match {
			correspondingWords = candidateWords
			// æ ‡è®°è¿™äº›å•è¯ä¸ºå·²ä½¿ç”¨
			for _, idx := range candidateIndices {
				usedIndices[idx] = true
			}
			break
		}
	}

	log.GetLogger().Debug("Found corresponding words with tracking",
		zap.String("originText", originText),
		zap.Int("foundWords", len(correspondingWords)))

	return correspondingWords
}

// parseSrtTimestamp è§£æSRTæ—¶é—´æˆ³æ ¼å¼ "HH:MM:SS,mmm --> HH:MM:SS,mmm"
func (s *YouTubeSubtitleService) parseSrtTimestamp(timestamp string) (float64, float64, error) {
	parts := strings.Split(timestamp, " --> ")
	if len(parts) != 2 {
		return 0, 0, fmt.Errorf("invalid SRT timestamp format: %s", timestamp)
	}

	startTime, err := s.parseSrtTime(parts[0])
	if err != nil {
		return 0, 0, fmt.Errorf("failed to parse start time: %w", err)
	}

	endTime, err := s.parseSrtTime(parts[1])
	if err != nil {
		return 0, 0, fmt.Errorf("failed to parse end time: %w", err)
	}

	return startTime, endTime, nil
}

// parseSrtTime è§£æå•ä¸ªSRTæ—¶é—´æ ¼å¼ "HH:MM:SS,mmm"
func (s *YouTubeSubtitleService) parseSrtTime(timeStr string) (float64, error) {
	// SRTæ ¼å¼: HH:MM:SS,mmm
	timeStr = strings.Replace(timeStr, ",", ".", 1) // è½¬æ¢ä¸ºVTTæ ¼å¼
	return s.parseVttTime(timeStr)
}

// convertToSrtTimestamp å°†VTTæ—¶é—´æˆ³æ ¼å¼è½¬æ¢ä¸ºSRTæ—¶é—´æˆ³æ ¼å¼
func (s *YouTubeSubtitleService) convertToSrtTimestamp(startTime, endTime string) (string, error) {
	// VTTæ ¼å¼: HH:MM:SS.mmm
	// SRTæ ¼å¼: HH:MM:SS,mmm
	srtStart := strings.Replace(startTime, ".", ",", 1)
	srtEnd := strings.Replace(endTime, ".", ",", 1)
	return fmt.Sprintf("%s --> %s", srtStart, srtEnd), nil
}

// splitBySmartRules æ™ºèƒ½åˆ†å¥ï¼šå½“æ²¡æœ‰æ ‡ç‚¹ç¬¦å·æ—¶ï¼Œä½¿ç”¨å¤šç§ç­–ç•¥åˆ†å¥
func (s *YouTubeSubtitleService) splitBySmartRules(words []VttWord) []Sentence {
	if len(words) == 0 {
		return nil
	}

	log.GetLogger().Info("Using smart sentence splitting strategies",
		zap.Int("total_words", len(words)))

	// å¯¹äºè¶…é•¿åºåˆ—ï¼ˆ>200ä¸ªå•è¯ï¼‰ï¼Œé‡‡ç”¨åˆ†å±‚å¤„ç†ç­–ç•¥
	if len(words) > 200 {
		return s.splitLargeSequenceByLayers(words)
	}

	var sentences []Sentence

	// ç­–ç•¥1: åŸºäºè¯­ä¹‰åˆ†å‰²ç‚¹ï¼ˆè¿è¯ã€ä»‹è¯ç­‰ï¼‰
	semanticSplits := s.splitBySemanticBreaks(words)
	if len(semanticSplits) > 1 {
		log.GetLogger().Info("Split by semantic breaks", zap.Int("result_sentences", len(semanticSplits)))
		sentences = append(sentences, semanticSplits...)
	} else {
		// ç­–ç•¥2: åŸºäºæ—¶é—´é—´éš”åˆ†å¥
		timeSplits := s.splitByTimeGaps(words)
		if len(timeSplits) > 1 {
			log.GetLogger().Info("Split by time gaps", zap.Int("result_sentences", len(timeSplits)))
			sentences = append(sentences, timeSplits...)
		} else {
			// ç­–ç•¥3: å›ºå®šé•¿åº¦åˆ†å¥ï¼ˆæœ€åçš„å¤‡ç”¨æ–¹æ¡ˆï¼‰
			lengthSplits := s.splitByFixedLength(words)
			log.GetLogger().Info("Split by fixed length", zap.Int("result_sentences", len(lengthSplits)))
			sentences = append(sentences, lengthSplits...)
		}
	}

	return sentences
}

// splitLargeSequenceByLayers åˆ†å±‚å¤„ç†è¶…é•¿åºåˆ—çš„æ™ºèƒ½åˆ†å¥
func (s *YouTubeSubtitleService) splitLargeSequenceByLayers(words []VttWord) []Sentence {
	log.GetLogger().Info("Using layered splitting for large sequence",
		zap.Int("total_words", len(words)))

	// ç¬¬ä¸€å±‚ï¼šæŒ‰æ—¶é—´é—´éš”è¿›è¡Œç²—åˆ†å‰²ï¼Œä½¿ç”¨æ›´å°çš„é˜ˆå€¼
	const roughTimeGapThreshold = 0.5 // 500æ¯«ç§’
	roughChunks := s.splitByTimeGapsWithThreshold(words, roughTimeGapThreshold)

	if len(roughChunks) <= 1 {
		// å¦‚æœæ—¶é—´åˆ†å‰²æ— æ•ˆï¼ŒæŒ‰å›ºå®šå¤§å°åˆ†å—
		roughChunks = s.splitIntoFixedChunks(words, 100) // æ¯å—100ä¸ªå•è¯
	}

	log.GetLogger().Info("First layer time-based rough splitting",
		zap.Int("rough_chunks", len(roughChunks)))

	var finalSentences []Sentence

	// ç¬¬äºŒå±‚ï¼šå¯¹æ¯ä¸ªæ—¶é—´å—åº”ç”¨è¯­ä¹‰åˆ†å‰²
	for i, chunk := range roughChunks {
		log.GetLogger().Debug("Processing chunk", zap.Int("chunk_index", i),
			zap.Int("chunk_words", len(chunk.Words)))

		// å¯¹æ¯ä¸ªå—ä½¿ç”¨å¸¸è§„æ™ºèƒ½åˆ†å¥
		chunkSentences := s.applySplittingStrategies(chunk.Words)
		finalSentences = append(finalSentences, chunkSentences...)
	}

	log.GetLogger().Info("Layered splitting completed",
		zap.Int("original_words", len(words)),
		zap.Int("final_sentences", len(finalSentences)))

	return finalSentences
}

// splitByTimeGapsWithThreshold ä½¿ç”¨æŒ‡å®šé˜ˆå€¼æŒ‰æ—¶é—´é—´éš”åˆ†å¥
func (s *YouTubeSubtitleService) splitByTimeGapsWithThreshold(words []VttWord, thresholdSeconds float64) []Sentence {
	if len(words) <= 3 {
		return []Sentence{s.createSentenceFromWords(words)}
	}

	var sentences []Sentence
	var currentWords []VttWord

	for i, word := range words {
		currentWords = append(currentWords, word)

		// æ£€æŸ¥ä¸ä¸‹ä¸€ä¸ªè¯çš„æ—¶é—´é—´éš”
		if i < len(words)-1 {
			currentEnd, err := s.parseVttTime(word.End)
			if err != nil {
				continue
			}
			nextStart, err := s.parseVttTime(words[i+1].Start)
			if err != nil {
				continue
			}

			timeGap := nextStart - currentEnd

			// å¦‚æœæ—¶é—´é—´éš”è¾ƒå¤§ä¸”å½“å‰å¥å­æœ‰è¶³å¤Ÿé•¿åº¦ï¼Œåˆ†å¥
			if timeGap >= thresholdSeconds && len(currentWords) >= 3 {
				sentence := s.createSentenceFromWords(currentWords)
				sentences = append(sentences, sentence)
				currentWords = []VttWord{} // é‡ç½®
			}
		}
	}

	// å¤„ç†å‰©ä½™çš„å•è¯
	if len(currentWords) > 0 {
		sentence := s.createSentenceFromWords(currentWords)
		sentences = append(sentences, sentence)
	}

	// å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆåˆ†å‰²ç‚¹ï¼ŒæŒ‰å›ºå®šå¤§å°åˆ†å—
	if len(sentences) <= 1 {
		return s.splitIntoFixedChunks(words, 50) // æ¯å—50ä¸ªå•è¯
	}

	return sentences
}

// splitIntoFixedChunks æŒ‰å›ºå®šå•è¯æ•°é‡åˆ†å—
func (s *YouTubeSubtitleService) splitIntoFixedChunks(words []VttWord, chunkSize int) []Sentence {
	var chunks []Sentence

	for i := 0; i < len(words); i += chunkSize {
		end := i + chunkSize
		if end > len(words) {
			end = len(words)
		}

		chunk := s.createSentenceFromWords(words[i:end])
		chunks = append(chunks, chunk)
	}

	return chunks
}

// applySplittingStrategies å¯¹å•ä¸ªå—åº”ç”¨åˆ†å¥ç­–ç•¥
func (s *YouTubeSubtitleService) applySplittingStrategies(words []VttWord) []Sentence {
	if len(words) == 0 {
		return nil
	}

	// ç­–ç•¥1: åŸºäºè¯­ä¹‰åˆ†å‰²ç‚¹
	semanticSplits := s.splitBySemanticBreaks(words)
	if len(semanticSplits) > 1 && !s.hasVeryShortSentences(semanticSplits) {
		return semanticSplits
	}

	// ç­–ç•¥2: åŸºäºæ—¶é—´é—´éš”
	timeSplits := s.splitByTimeGaps(words)
	if len(timeSplits) > 1 && !s.hasVeryShortSentences(timeSplits) {
		return timeSplits
	}

	// ç­–ç•¥3: å›ºå®šé•¿åº¦åˆ†å¥ï¼ˆæœ€åçš„å¤‡ç”¨æ–¹æ¡ˆï¼‰
	return s.splitByFixedLength(words)
}

// splitBySemanticBreaks åŸºäºè¯­ä¹‰åˆ†å‰²ç‚¹åˆ†å¥ï¼ˆè¿è¯ã€è¿‡æ¸¡è¯ç­‰ï¼‰
func (s *YouTubeSubtitleService) splitBySemanticBreaks(words []VttWord) []Sentence {
	if len(words) <= 5 {
		return []Sentence{s.createSentenceFromWords(words)}
	}

	// ä¼˜åŒ–åçš„è¯­ä¹‰åˆ†å‰²æ ‡å¿—è¯ - æ›´æ³¨é‡å¥å­å®Œæ•´æ€§
	strongBreakWords := map[string]bool{
		// å¼ºåˆ†å‰²è¯ï¼šé€šå¸¸æ ‡å¿—æ–°å¥å­æˆ–ç‹¬ç«‹ä»å¥çš„å¼€å§‹
		"however": true, "therefore": true, "moreover": true, "furthermore": true,
		"nonetheless": true, "meanwhile": true, "afterwards": true, "consequently": true,
		"additionally": true, "besides": true, "similarly": true, "likewise": true,
		"nevertheless": true, "subsequently": true, "alternatively": true,
		// æ—¶é—´å’Œé¡ºåºæ ‡å¿—è¯
		"first": true, "second": true, "third": true, "finally": true, "lastly": true,
		"next": true, "then": true, "now": true, "later": true, "previously": true,
		// æ¡ä»¶å’Œå¯¹æ¯”è¯
		"although": true, "though": true, "whereas": true, "despite": true,
	}

	// å¼±åˆ†å‰²è¯ï¼šåªåœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­åˆ†å‰²ï¼Œéœ€è¦æ›´å¤šæ¡ä»¶
	contextualBreakWords := map[string]bool{
		"and": true, "but": true, "or": true, "so": true,
		"because": true, "since": true, "when": true, "while": true,
		"if": true, "unless": true, "until": true, "before": true,
		"after": true, "during": true,
	}

	var sentences []Sentence
	var currentWords []VttWord
	minSentenceLength := 5 // æœ€å°å¥å­é•¿åº¦ï¼ˆå•è¯æ•°ï¼‰

	for i, word := range words {
		currentWords = append(currentWords, word)
		wordLower := strings.ToLower(strings.TrimSpace(word.Text))

		shouldBreak := false

		// æ£€æŸ¥å¼ºåˆ†å‰²è¯
		if strongBreakWords[wordLower] && len(currentWords) >= minSentenceLength {
			shouldBreak = true
		}

		// æ£€æŸ¥å¼±åˆ†å‰²è¯ï¼Œéœ€è¦é¢å¤–æ¡ä»¶
		if !shouldBreak && contextualBreakWords[wordLower] && len(currentWords) >= minSentenceLength {
			// é¢å¤–æ¡ä»¶ï¼šç¡®ä¿å‰é¢æœ‰å®Œæ•´çš„ä¸»è°“ç»“æ„
			if s.hasCompletePhrase(currentWords[:len(currentWords)-1]) {
				shouldBreak = true
			}
		}

		// å¦‚æœæ»¡è¶³åˆ†å‰²æ¡ä»¶ä¸”ä¸æ˜¯æœ€åä¸€ä¸ªè¯
		if shouldBreak && i < len(words)-1 {
			// åˆ›å»ºå¥å­ï¼Œä½†ä¸åŒ…å«åˆ†å‰²è¯ï¼ˆåˆ†å‰²è¯æ”¾åˆ°ä¸‹ä¸€å¥å¼€å¤´ï¼‰
			if len(currentWords) > 1 {
				sentence := s.createSentenceFromWords(currentWords[:len(currentWords)-1])
				sentences = append(sentences, sentence)
				currentWords = []VttWord{word} // åˆ†å‰²è¯ä½œä¸ºä¸‹ä¸€å¥çš„å¼€å¤´
			}
		}
	}

	// å¤„ç†å‰©ä½™çš„å•è¯
	if len(currentWords) > 0 {
		sentence := s.createSentenceFromWords(currentWords)
		sentences = append(sentences, sentence)
	}

	// å¦‚æœåˆ†å‰²ç»“æœä¸ç†æƒ³ï¼Œè¿”å›ç©º
	if len(sentences) <= 1 || s.hasVeryShortSentences(sentences) {
		return []Sentence{}
	}

	return sentences
}

// hasCompletePhrase æ£€æŸ¥è¯ç»„æ˜¯å¦åŒ…å«å®Œæ•´çš„ä¸»è°“ç»“æ„æˆ–æ„ä¹‰å•å…ƒ
func (s *YouTubeSubtitleService) hasCompletePhrase(words []VttWord) bool {
	if len(words) < 3 {
		return false
	}

	text := strings.ToLower(strings.Join(s.extractTextsFromWords(words), " "))

	// æ£€æŸ¥æ˜¯å¦åŒ…å«åŠ¨è¯æŒ‡ç¤ºè¯ï¼ˆç®€å•å¯å‘å¼ï¼‰
	verbIndicators := []string{
		"am", "is", "are", "was", "were", "be", "been", "being",
		"have", "has", "had", "do", "does", "did", "will", "would", "could", "should",
		"can", "may", "might", "must", "shall",
		"go", "goes", "went", "come", "comes", "came", "get", "gets", "got",
		"make", "makes", "made", "take", "takes", "took", "give", "gives", "gave",
		"see", "sees", "saw", "know", "knows", "knew", "think", "thinks", "thought",
		"say", "says", "said", "tell", "tells", "told", "want", "wants", "wanted",
		"need", "needs", "needed", "like", "likes", "liked", "work", "works", "worked",
	}

	for _, verb := range verbIndicators {
		if strings.Contains(text, " "+verb+" ") || strings.HasPrefix(text, verb+" ") {
			return true
		}
	}

	return false
}

// hasVeryShortSentences æ£€æŸ¥æ˜¯å¦æœ‰è¿‡çŸ­çš„å¥å­
func (s *YouTubeSubtitleService) hasVeryShortSentences(sentences []Sentence) bool {
	for _, sentence := range sentences {
		words := strings.Fields(sentence.Text)
		if len(words) < 3 {
			return true
		}
	}
	return false
}

// extractTextsFromWords ä»VttWordæ•°ç»„ä¸­æå–æ–‡æœ¬æ•°ç»„
func (s *YouTubeSubtitleService) extractTextsFromWords(words []VttWord) []string {
	texts := make([]string, len(words))
	for i, word := range words {
		texts[i] = word.Text
	}
	return texts
}

// splitByTimeGaps åŸºäºæ—¶é—´é—´éš”åˆ†å¥ï¼ˆæ£€æµ‹è¾ƒé•¿çš„åœé¡¿ï¼‰
func (s *YouTubeSubtitleService) splitByTimeGaps(words []VttWord) []Sentence {
	if len(words) <= 3 {
		return []Sentence{s.createSentenceFromWords(words)}
	}

	var sentences []Sentence
	var currentWords []VttWord

	// è®¾ç½®æ—¶é—´é—´éš”é˜ˆå€¼ï¼ˆç§’ï¼‰
	const timeGapThreshold = 0.8 // 800æ¯«ç§’

	for i, word := range words {
		currentWords = append(currentWords, word)

		// æ£€æŸ¥ä¸ä¸‹ä¸€ä¸ªè¯çš„æ—¶é—´é—´éš”
		if i < len(words)-1 {
			currentEnd, err := s.parseVttTime(word.End)
			if err != nil {
				continue
			}
			nextStart, err := s.parseVttTime(words[i+1].Start)
			if err != nil {
				continue
			}

			timeGap := nextStart - currentEnd

			// å¦‚æœæ—¶é—´é—´éš”è¾ƒå¤§ä¸”å½“å‰å¥å­æœ‰è¶³å¤Ÿé•¿åº¦ï¼Œåˆ†å¥
			if timeGap >= timeGapThreshold && len(currentWords) >= 3 {
				sentence := s.createSentenceFromWords(currentWords)
				sentences = append(sentences, sentence)
				currentWords = []VttWord{} // é‡ç½®
			}
		}
	}

	// å¤„ç†å‰©ä½™çš„å•è¯
	if len(currentWords) > 0 {
		sentence := s.createSentenceFromWords(currentWords)
		sentences = append(sentences, sentence)
	}

	// å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆåˆ†å‰²ç‚¹ï¼Œè¿”å›ç©º
	if len(sentences) <= 1 {
		return []Sentence{}
	}

	return sentences
}

// splitByFixedLength æŒ‰å›ºå®šé•¿åº¦åˆ†å¥ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰ï¼Œä¼˜åŒ–ä»¥é¿å…åœ¨å…³é”®è¯ä¸­é—´åˆ†å‰²
func (s *YouTubeSubtitleService) splitByFixedLength(words []VttWord) []Sentence {
	if len(words) == 0 {
		return nil
	}

	var sentences []Sentence
	var currentWords []VttWord

	// ä¼˜åŒ–å›ºå®šé•¿åº¦ç­–ç•¥ï¼šç›®æ ‡é•¿åº¦10-15ä¸ªå•è¯ï¼Œä½†é¿å…åœ¨ä¸åˆé€‚çš„åœ°æ–¹åˆ†å‰²
	const targetLength = 12
	const minLength = 8
	const maxLength = 18

	// ä¸é€‚åˆä½œä¸ºå¥å­ç»“å°¾çš„è¯
	badEndWords := map[string]bool{
		"a": true, "an": true, "the": true,
		"of": true, "in": true, "on": true, "at": true, "to": true, "for": true,
		"with": true, "by": true, "from": true, "about": true,
		"and": true, "but": true, "or": true,
		"is": true, "am": true, "are": true, "was": true, "were": true,
		"have": true, "has": true, "had": true,
		"will": true, "would": true, "could": true, "should": true,
		"my": true, "your": true, "his": true, "her": true, "its": true, "our": true, "their": true,
		"this": true, "that": true, "these": true, "those": true,
		// æ–°å¢ï¼šå¸¸è§çš„ä¸é€‚åˆç‹¬ç«‹æˆå¥çš„è¯
		"up": true, "down": true, "out": true, "off": true, "away": true, "back": true,
		"into": true, "onto": true, "upon": true, "within": true, "without": true,
		"through": true, "across": true, "under": true, "over": true,
		"before": true, "after": true, "during": true, "since": true, "until": true,
		"can": true, "may": true, "might": true, "must": true, "shall": true,
		"not": true, "never": true, "always": true, "often": true, "sometimes": true,
		"very": true, "quite": true, "really": true, "just": true, "only": true,
		"more": true, "most": true, "less": true, "least": true, "much": true,
		"too": true, "so": true, "such": true, "even": true, "still": true,
	}

	// å¸¸è§çš„ä¸åº”è¯¥è¢«åˆ†å‰²çš„çŸ­è¯­å’Œå›ºå®šæ­é…
	commonPhrases := [][]string{
		{"fall", "apart"}, {"break", "down"}, {"give", "up"}, {"take", "off"},
		{"put", "on"}, {"turn", "off"}, {"turn", "on"}, {"look", "up"},
		{"look", "down"}, {"come", "back"}, {"go", "away"}, {"walk", "away"},
		{"run", "away"}, {"get", "up"}, {"sit", "down"}, {"stand", "up"},
		{"wake", "up"}, {"grow", "up"}, {"pick", "up"}, {"drop", "off"},
		{"find", "out"}, {"figure", "out"}, {"work", "out"}, {"sort", "out"},
		{"carry", "on"}, {"move", "on"}, {"hold", "on"}, {"hang", "on"},
		{"right", "now"}, {"right", "away"}, {"right", "here"}, {"right", "there"},
		{"all", "over"}, {"all", "around"}, {"all", "along"}, {"all", "together"},
		{"once", "again"}, {"over", "again"}, {"time", "after", "time"},
		{"day", "after", "day"}, {"year", "after", "year"}, {"forever"},
		{"for", "good"}, {"for", "sure"}, {"for", "real"}, {"for", "now"},
		{"at", "all"}, {"at", "once"}, {"at", "last"}, {"at", "first"},
		{"in", "fact"}, {"in", "general"}, {"in", "particular"}, {"in", "short"},
		{"on", "purpose"}, {"on", "time"}, {"by", "chance"}, {"by", "accident"},
		{"lose", "touch"}, {"get", "lost"}, {"make", "sense"}, {"take", "care"},
	}

	for i, word := range words {
		currentWords = append(currentWords, word)
		currentLength := len(currentWords)

		// åˆ¤æ–­æ˜¯å¦åº”è¯¥åœ¨æ­¤å¤„åˆ†å‰²
		shouldSplit := false

		if currentLength >= maxLength {
			// è¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œå¿…é¡»åˆ†å‰²
			shouldSplit = true
		} else if currentLength >= targetLength {
			// è¾¾åˆ°ç›®æ ‡é•¿åº¦ï¼Œå¯»æ‰¾åˆé€‚çš„åˆ†å‰²ç‚¹
			wordText := strings.ToLower(strings.TrimSpace(word.Text))

			// æ£€æŸ¥æ˜¯å¦ä¸ºä¸è‰¯ç»“å°¾è¯
			if !badEndWords[wordText] {
				// è¿›ä¸€æ­¥æ£€æŸ¥æ˜¯å¦ä¼šåˆ†å‰²å¸¸è§çŸ­è¯­
				if !s.wouldSplitCommonPhrase(currentWords, words, i, commonPhrases) {
					shouldSplit = true
				}
			}
		} else if i == len(words)-1 {
			// æœ€åä¸€ä¸ªè¯ï¼Œå¿…é¡»ç»“æŸ
			shouldSplit = true
		}

		// æ‰§è¡Œåˆ†å‰²
		if shouldSplit && currentLength >= minLength {
			sentence := s.createSentenceFromWords(currentWords)
			sentences = append(sentences, sentence)
			currentWords = []VttWord{} // é‡ç½®
		} else if shouldSplit && currentLength < minLength && i == len(words)-1 {
			// å¦‚æœæ˜¯æœ€åä¸€å¥ä½†é•¿åº¦ä¸å¤Ÿï¼Œä»ç„¶åˆ›å»ºå¥å­
			sentence := s.createSentenceFromWords(currentWords)
			sentences = append(sentences, sentence)
			currentWords = []VttWord{} // é‡ç½®
		}
	}

	// å¤„ç†å¯èƒ½å‰©ä½™çš„å•è¯ï¼ˆè™½ç„¶ç†è®ºä¸Šä¸åº”è¯¥æœ‰ï¼‰
	if len(currentWords) > 0 {
		if len(sentences) > 0 {
			// å¦‚æœå·²ç»æœ‰å¥å­ï¼Œå°†å‰©ä½™è¯åˆå¹¶åˆ°æœ€åä¸€å¥
			lastIdx := len(sentences) - 1
			lastSentence := &sentences[lastIdx]

			// é‡æ–°åˆ›å»ºåŒ…å«æ‰€æœ‰è¯çš„å¥å­
			allWords := s.extractWordsFromSentence(*lastSentence)
			allWords = append(allWords, currentWords...)
			*lastSentence = s.createSentenceFromWords(allWords)
		} else {
			// å¦‚æœæ²¡æœ‰å¥å­ï¼Œåˆ›å»ºä¸€ä¸ªæ–°å¥å­
			sentence := s.createSentenceFromWords(currentWords)
			sentences = append(sentences, sentence)
		}
	}

	// åå¤„ç†ï¼šåˆå¹¶è¿‡çŸ­çš„å¥å­
	sentences = s.mergeVeryShortSentences(sentences)

	log.GetLogger().Info("Optimized fixed length splitting completed",
		zap.Int("original_words", len(words)),
		zap.Int("created_sentences", len(sentences)),
		zap.Int("target_length", targetLength))

	return sentences
}

// extractWordsFromSentence ä»å¥å­ä¸­æå–VttWordï¼ˆç”¨äºåˆå¹¶å¥å­ï¼‰
func (s *YouTubeSubtitleService) extractWordsFromSentence(sentence Sentence) []VttWord {
	// ç›´æ¥è¿”å›å¥å­ä¸­å·²æœ‰çš„å•è¯æ•°æ®
	return sentence.Words
}

// wouldSplitCommonPhrase æ£€æŸ¥åœ¨å½“å‰ä½ç½®åˆ†å‰²æ˜¯å¦ä¼šåˆ†å¼€å¸¸è§çŸ­è¯­
func (s *YouTubeSubtitleService) wouldSplitCommonPhrase(currentWords, allWords []VttWord, currentIndex int, commonPhrases [][]string) bool {
	if len(currentWords) == 0 || currentIndex >= len(allWords)-1 {
		return false
	}

	// è·å–å½“å‰å¥å­æœ«å°¾çš„å‡ ä¸ªè¯
	endWords := make([]string, 0, 3)
	for i := max(0, len(currentWords)-3); i < len(currentWords); i++ {
		endWords = append(endWords, strings.ToLower(strings.TrimSpace(currentWords[i].Text)))
	}

	// è·å–æ¥ä¸‹æ¥çš„å‡ ä¸ªè¯
	nextWords := make([]string, 0, 3)
	for i := currentIndex + 1; i < min(currentIndex+4, len(allWords)); i++ {
		nextWords = append(nextWords, strings.ToLower(strings.TrimSpace(allWords[i].Text)))
	}

	// æ£€æŸ¥æ˜¯å¦ä¼šåˆ†å‰²å¸¸è§çŸ­è¯­
	for _, phrase := range commonPhrases {
		if s.wouldSplitPhrase(endWords, nextWords, phrase) {
			return true
		}
	}

	return false
}

// wouldSplitPhrase æ£€æŸ¥æ˜¯å¦ä¼šåˆ†å‰²ç‰¹å®šçŸ­è¯­
func (s *YouTubeSubtitleService) wouldSplitPhrase(endWords, nextWords, phrase []string) bool {
	// æ„å»ºå®Œæ•´çš„è¯åºåˆ—
	allWords := append(endWords, nextWords...)

	// åœ¨è¯åºåˆ—ä¸­æŸ¥æ‰¾çŸ­è¯­
	for i := 0; i <= len(allWords)-len(phrase); i++ {
		match := true
		for j, phraseWord := range phrase {
			if i+j >= len(allWords) || allWords[i+j] != phraseWord {
				match = false
				break
			}
		}

		if match {
			// æ‰¾åˆ°çŸ­è¯­ï¼Œæ£€æŸ¥åˆ†å‰²ç‚¹æ˜¯å¦åœ¨çŸ­è¯­ä¸­é—´
			splitPoint := len(endWords)
			phraseStart := i
			phraseEnd := i + len(phrase)

			if splitPoint > phraseStart && splitPoint < phraseEnd {
				return true // ä¼šåˆ†å‰²è¿™ä¸ªçŸ­è¯­
			}
		}
	}

	return false
}

// mergeVeryShortSentences åˆå¹¶è¿‡çŸ­çš„å¥å­åˆ°å‰ä¸€å¥
func (s *YouTubeSubtitleService) mergeVeryShortSentences(sentences []Sentence) []Sentence {
	if len(sentences) <= 1 {
		return sentences
	}

	var result []Sentence
	const veryShortThreshold = 3 // å°‘äº3ä¸ªå•è¯è®¤ä¸ºæ˜¯è¿‡çŸ­

	for _, sentence := range sentences {
		words := strings.Fields(sentence.Text)

		if len(words) <= veryShortThreshold && len(result) > 0 {
			// å½“å‰å¥å­è¿‡çŸ­ï¼Œåˆå¹¶åˆ°å‰ä¸€å¥
			lastIdx := len(result) - 1
			prevSentence := &result[lastIdx]

			// åˆå¹¶å•è¯
			mergedWords := append(prevSentence.Words, sentence.Words...)

			// é‡æ–°åˆ›å»ºå¥å­
			*prevSentence = s.createSentenceFromWords(mergedWords)
		} else {
			// å¥å­é•¿åº¦æ­£å¸¸ï¼Œç›´æ¥æ·»åŠ 
			result = append(result, sentence)
		}
	}

	return result
}

// min è¿”å›ä¸¤ä¸ªintä¸­çš„è¾ƒå°å€¼
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// max è¿”å›ä¸¤ä¸ªintä¸­çš„è¾ƒå¤§å€¼
func max(a, b int) int {
	if a > b {
		return a
	}
	return b
}
